<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/assets/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/assets/apple-touch-icon.png"/><link rel="alternate" href="/rss.xml" title="跨越屏幕，幸识" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="跨越屏幕，幸识" type="application/atom+xml"><link rel="alternate" type="application/json" title="跨越屏幕，幸识" href="https://liuxiaohanhanzi.top/feed.json"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="preconnect" href="https://at.alicdn.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/css/app.css?v=0.4.20"><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/chunk-7FYK5Y66.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/chunk-DANOFLES.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/chunk-QX3HMU3P.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/chunk-UXOTYCNZ.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/chunk-VZBYTPJL.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/copy-tex-Q3RDRIPH.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/index.esm-Y7WUAPSF.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/post-ABVK2UKY.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/quicklink-5N6WAHAU.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/search-TAWO3Y22.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/siteInit.js"></link><link rel="modulepreload" href="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/tcomments-MVBCPY35.js"></link><link rel="preload" href="https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021435268.jpg" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021433715.png" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021435460.jpg" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021434976.png" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021435615.jpg" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021434370.png" as="image" fetchpriority="high"><meta name="keywords" content="大模型"/><meta name="description" content="What is &quot;LOVE&quot; ?"/><link rel="canonical" href="https://liuxiaohanhanzi.top/LLM/LLM%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/"><title>LLM推理加速</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">LLM推理加速</h1><div class="meta"><span class="item" title="创建时间：2025-03-25 18:38:30"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2025-03-25T18:38:30+08:00">2025-03-25</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>3k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>3 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Liuxiaohanhanzi</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><ul><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021435268.jpg&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021433715.png&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021435460.jpg&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021434976.png&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021435615.jpg&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/liuxiaohanhanzi/blog-img/img/202502021434370.png&quot;);"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/LLM/" itemprop="item" rel="index" title="分类于LLM"><span itemprop="name">LLM<meta itemprop="position" content="0"/></span></a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://liuxiaohanhanzi.top/LLM/LLM%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/assets/avatar.jpg"/><meta itemprop="name" content="柳小寒寒子"/><meta itemprop="description" content=", What is &quot;LOVE&quot; ?"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="跨越屏幕，幸识"/></span><div class="body md" itemprop="articleBody"><h1 id="gpu内存概论"><a class="anchor" href="#gpu内存概论">#</a> GPU 内存概论</h1>
<blockquote>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/video/BV1rH4y1c7Zs/?share_source=copy_web&amp;vd_source=f0a4a59c7013e34588e9395814ec45a9">参考视频</a></p>
</blockquote>
<img loading="lazy" data-src="./image-20250619151517330.png" alt="image-20250619151517330" width="75%" />
<p>如上图，DRAM 用于电脑内存；HBM 用于芯片外显卡显存；SRAM 用于 GPU 芯片内，如 L1 Cache、L2 Cache；</p>
<p>GPU 内有大量 Core 和 thread，使用 SIMT（单一指令，多线程执行）技术，比如矩阵乘法里结果里的每个元素可以分配一个线程。32 个线程一组，叫做一个 Warp。Warp 是 GPU 里调度任务的最小单元。</p>
<p>GPU 由大量的块组成，每个块称作一个 SM（流式处理器），一个 SM 结构如下：</p>
<p><img loading="lazy" data-src="./image-20250619163916030.png" alt="image-20250619163916030" /></p>
<p>由于显存传输相对慢，计算单元更快更空闲，因此我们希望减少 GPU 空闲 ——<br />
 因为矩阵乘法的计算时间复杂度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，空间复杂度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>所以切分矩阵维度即可：</p>
<ul>
<li>数据传输的慢，用大矩阵</li>
<li>数据传输快，用小矩阵</li>
</ul>
<blockquote>
<p><em>但是如果传输慢、矩阵还小，就没辙了</em></p>
</blockquote>
<hr />
<p>回到大模型加速，根据论文《A Survey on Efficient Inference for Large Language Models》，我做了如下总结。</p>
<p>LLM 推理的三大成本：</p>
<ul>
<li>计算成本</li>
<li>内存访问成本</li>
<li>内存占用成本</li>
</ul>
<p>对大模型的推理加速流派做一个总结，分类如下图：</p>
<p><img loading="lazy" data-src="./framework.png" alt="framework" /></p>
<h1 id="数据层优化"><a class="anchor" href="#数据层优化">#</a> 数据层优化</h1>
<h2 id="输入压缩技术"><a class="anchor" href="#输入压缩技术">#</a> 输入压缩技术</h2>
<p><strong>提示词剪枝</strong>：即去除提示词里的废话，保留有用信息</p>
<p><strong>提示词总结</strong>：对很长的提示词（整篇 word）概括一个 summary，以此作为提示词的浓缩交给模型</p>
<p><strong>软提示词</strong>：在输入文本前加入一些向量，这些向量可以激活大模型某一方面的知识，然后得到更好的效果。软提示词是可训练迭代的向量，先冻结大模型的参数，推理微调，更新软提示词；不断循环直到软提示词效果不错，不改了 —— 最后推理就是最终结果；一次训练，多次推理。</p>
<p><strong>检索增强生成</strong>（RAG）：也就是所谓的大模型联网。通过检索和输入相关的辅助内容，并只将这些相关的内容加入到输入提示词中，来降低原本的输入长度（相比于加入所有辅助内容）</p>
<h2 id="输出规划技术"><a class="anchor" href="#输出规划技术">#</a> 输出规划技术</h2>
<p>规划输出内容，尽量并行生成某些部分的，以此优化推理延时。比如思维骨架方法（SoT），最终回复依总分结构并行生成，如下图：</p>
<p><img loading="lazy" data-src="./sot_demo.png" alt="sot_demo" /></p>
<h1 id="模型层优化"><a class="anchor" href="#模型层优化">#</a> 模型层优化</h1>
<h2 id="高效结构设计改变模型"><a class="anchor" href="#高效结构设计改变模型">#</a> 高效结构设计（改变模型）</h2>
<ul>
<li>
<p>改造 FFN：比如 MOE 技术，还有 deepseek 搞的更多专家激活、共享基础知识的 MOE</p>
</li>
<li>
<p>改造 MHA：</p>
<ul>
<li>共享 KV 的 多询问注意力技术（Multi-Query）</li>
<li>核函数算子替换 softmax，就是换一种激活方式，把碍事贼拉慢的 softmax 换掉，从<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> 变成<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(Nd)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span></li>
<li>低秩算子，如 Linformer（每个 token 的钥匙不变，把 KV 信息量维度压缩，比如压缩为 128 个锁 &amp; 对应信息），于是获得线性复杂度<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>r</mi><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(Nrd)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>；</li>
</ul>
</li>
<li>
<p>寻找线性架构替代 Transformer</p>
</li>
</ul>
<h2 id="模型压缩简化模型"><a class="anchor" href="#模型压缩简化模型">#</a> 模型压缩（简化模型）</h2>
<h3 id="量化"><a class="anchor" href="#量化">#</a> 量化</h3>
<p>量化就是通过 scaling 或者 bias，将模型参数与输入激活值，从 fp32、fp16 转化为 int8，加速计算与内存 IO；量化可分为 ——</p>
<ol>
<li>训练后量化</li>
</ol>
<p><img loading="lazy" data-src="./image-20250619151020209.png" alt="image-20250619151020209" /></p>
<ol start="2">
<li>训练感知量化</li>
</ol>
<p><img loading="lazy" data-src="./image-20250619150940815.png" alt="image-20250619150940815" /></p>
<h3 id="模型稀疏"><a class="anchor" href="#模型稀疏">#</a> 模型稀疏</h3>
<ol>
<li>权重稀疏</li>
</ol>
<p>又称作权值剪枝，即从模型中去除不太关键的权值和结构。这种稀疏化方法分为两种主要类型：非结构化修剪和结构化修剪。非结构化剪的细、预测影响小，但是不规则，会阻碍硬件加速能力；结构化一剪剪一个 channel/layer/group；后者更有用</p>
<p><img loading="lazy" data-src="./pruning.png" alt="pruning" /></p>
<ol start="2">
<li>注意力稀疏</li>
</ol>
<p>就是注意力信息不把整个句子全算，只算一部分。比如对每个 token，算他 &lt;邻近的&gt;+&lt; 全局头部 &gt;+&lt; 随机 &gt;</p>
<p><img loading="lazy" data-src="./sparse_attention.jpg" alt="sparse_attention" /></p>
<h3 id="结构优化"><a class="anchor" href="#结构优化">#</a> 结构优化</h3>
<ul>
<li>神经网络架构搜索</li>
</ul>
<p>先定义好 “候选网络” 的积木组件 —— 例如可以有哪些层（卷积、池化、激活等）、每层能选的超参数、网络层之间怎么连接；然后让机器自己探索，选出最优架构。对于大模型不太能用，因为探索时要试错，要训练，cost 太大</p>
<ul>
<li>低秩分解（如 LoRA）</li>
</ul>
<p>把一个大的权重矩阵分解成两个小矩阵相乘，降低 LLM 的权重的存储开销和访存开销，从<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 变为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span></p>
<h3 id="知识蒸馏"><a class="anchor" href="#知识蒸馏">#</a> 知识蒸馏</h3>
<p>用一个大模型（教师模型）来辅助训练一个小模型（学生模型），从而将大模型的知识传递给小模型，通过小模型更小的开销达到相似的精度效果。</p>
<ul>
<li>白盒：可以获得教师模型的架构和权重，利用更多信息（特征、输出概率等）训练学生模型</li>
<li>黑盒：只能获取输出，所以需要构造数据训练学生模型</li>
</ul>
<h3 id="动态推理条件计算"><a class="anchor" href="#动态推理条件计算">#</a> 动态推理（条件计算）</h3>
<p>在模型中插入 “小判断器”（Router、Gate 或者 Early Exit Module），负责评估当前数据是否 “简单” 或 “困难”，并决定 “是否跳过后面层 / 通道”，或提前输出结果。</p>
<p>例如，模型做完某层后，判断 “我确定预测为猫？”，如果信心够高，就可以直接输出，无需继续深层计算。</p>
<h1 id="系统层优化"><a class="anchor" href="#系统层优化">#</a> 系统层优化</h1>
<h2 id="推理引擎"><a class="anchor" href="#推理引擎">#</a> 推理引擎</h2>
<ul>
<li>图和算子优化</li>
</ul>
<p>翻译的太怪了…… 还有算子这个翻译，明明意思就是 “一个计算步骤”，无力吐槽</p>
<ol>
<li>
<p>所谓图优化，其实就是着眼于多个算子组合在一起的整个计算流程，进行流程重构与优化，比如</p>
<ul>
<li>
<p>“把  <code>Conv + ReLU</code>  合并为一个高效运算，消除重复计算”</p>
</li>
<li>
<p>“把  <code>MatMul + Transpose</code>  换成支持转置的  <code>MatMul</code> ”，多步合成一步</p>
</li>
</ul>
</li>
<li>
<p>算子优化就是优化一个计算操作（著名代表 FlashAttention ），比如</p>
<ul>
<li>
<p>对  <code>MatMul</code> 、 <code>Conv</code> 、 <code>Softmax</code>  等算子，使用硬件平台（如 NVIDIA、Intel、ARM）的<strong>底层高效版本</strong></p>
</li>
<li>
<p>在一个 kernel 中串行执行多个操作，减少中间数据读写</p>
</li>
<li>
<p>矩阵分块（tiling），减少显存 IO</p>
</li>
</ul>
</li>
</ol>
<ul>
<li>推测解码</li>
</ul>
<p>使用一个便宜的小模型（被称为草稿模型）来预测未来的若干个词块，再用大模型并行地验证这些词块是否准确。</p>
<h2 id="服务系统"><a class="anchor" href="#服务系统">#</a> 服务系统</h2>
<p>就是硬件相关加速技术，看不懂了…… 很底层</p>
<div class="tags"><a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag"><i class="ic i-tag"></i>大模型</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-eye"></i></span><span class="text">总访问量：</span><span class="waline-pageview-count" id="twikoo_visitors" data-path="/LLM/LLM推理加速/">加载中...</span></span><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于 </span><time title="修改时间：2025-06-19 18:03:20" itemprop="dateModified" datetime="2025-06-19T18:03:20+08:00">2025-06-19</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>赞赏</button><p>谢谢你请我喝[茶]！(๑OvO๑)♪</p><div id="qr"><div><img loading="lazy" data-src="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/assets/wechatpay.png" alt="柳小寒寒子 微信支付"/><p>微信支付</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>柳小寒寒子<i class="ic i-at"><em>@</em></i>跨越屏幕，幸识</li><li class="link"><strong>本文链接：</strong><a href="https://liuxiaohanhanzi.top/LLM/LLM%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/" title="LLM推理加速">https://liuxiaohanhanzi.top/LLM/LLM推理加速/</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/quant/technical/%E6%8A%80%E6%9C%AF%E9%9D%A2%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89%EF%BC%89/" rel="prev" itemprop="url" title="技术面学习（三）" style="background-image: linear-gradient(to bottom right, #fadd82, #b197dc);"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>技术面</span><h3>技术面学习（三）</h3></a></div><div class="item right"><a href="/internship/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81%E5%88%9D%E7%AA%A5/" rel="next" itemprop="url" title="数字货币初窥" style="background-image: linear-gradient(to bottom right, #e0c7b2, #b0a5ee);"><span class="type">下一篇</span><span class="category"><i class="ic i-flag"></i>实习</span><h3>数字货币初窥</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#gpu%E5%86%85%E5%AD%98%E6%A6%82%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text"> GPU 内存概论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B1%82%E4%BC%98%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text"> 数据层优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E5%8E%8B%E7%BC%A9%E6%8A%80%E6%9C%AF"><span class="toc-number">2.1.</span> <span class="toc-text"> 输入压缩技术</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E8%A7%84%E5%88%92%E6%8A%80%E6%9C%AF"><span class="toc-number">2.2.</span> <span class="toc-text"> 输出规划技术</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%B1%82%E4%BC%98%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text"> 模型层优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%94%B9%E5%8F%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.</span> <span class="toc-text"> 高效结构设计（改变模型）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E7%AE%80%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text"> 模型压缩（简化模型）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E5%8C%96"><span class="toc-number">3.2.1.</span> <span class="toc-text"> 量化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%A8%80%E7%96%8F"><span class="toc-number">3.2.2.</span> <span class="toc-text"> 模型稀疏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96"><span class="toc-number">3.2.3.</span> <span class="toc-text"> 结构优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="toc-number">3.2.4.</span> <span class="toc-text"> 知识蒸馏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E6%8E%A8%E7%90%86%E6%9D%A1%E4%BB%B6%E8%AE%A1%E7%AE%97"><span class="toc-number">3.2.5.</span> <span class="toc-text"> 动态推理（条件计算）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E5%B1%82%E4%BC%98%E5%8C%96"><span class="toc-number">4.</span> <span class="toc-text"> 系统层优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E"><span class="toc-number">4.1.</span> <span class="toc-text"> 推理引擎</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E7%B3%BB%E7%BB%9F"><span class="toc-number">4.2.</span> <span class="toc-text"> 服务系统</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li  class="active"><a href="/LLM/LLM%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/" rel="bookmark" title="LLM推理加速">LLM推理加速</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="柳小寒寒子" src="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/assets/avatar.jpg"/><p class="name" itemprop="name">柳小寒寒子</p><div class="description" itemprop="description">What is "LOVE" ?</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">67</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">14</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">25</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/liuxiaohanhanzi" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;liuxiaohanhanzi"><i class="ic i-github"></i></a><a target="_blank" rel="noopener external nofollow noreferrer" href="https://gitee.com/liuxiaohanhanzi" class="item gitee" title="https:&#x2F;&#x2F;gitee.com&#x2F;liuxiaohanhanzi"><i class="ic i-gitee"></i></a><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.zhihu.com/people/liu-han-7-80" class="item zhihu" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;liu-han-7-80"><i class="ic i-zhihu"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/internship/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81%E5%88%9D%E7%AA%A5/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/quant/technical/%E6%8A%80%E6%9C%AF%E9%9D%A2%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89%EF%BC%89/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/world-me/" title="分类于对世界的建模">对世界的建模</a></div><span><a href="/world-me/kazeohamu-%E9%A2%A8%E3%82%92%E9%A3%9F%E3%82%80/">kazeohamu(風を食む)</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/quant/" title="分类于量化">量化</a><i class="ic i-angle-right"></i><a href="/categories/quant/c-fundamental/" title="分类于基本面">基本面</a></div><span><a href="/quant/c-fundamental/%E5%9F%BA%E6%9C%AC%E9%9D%A2%E9%87%8F%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%9B%9B%EF%BC%89/">基本面量化学习（四）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/blog-construction/" title="分类于博客搭建">博客搭建</a></div><span><a href="/blog-construction/ShokaX%E6%9B%B4%E6%96%B0/">ShokaX更新</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/quant/" title="分类于量化">量化</a><i class="ic i-angle-right"></i><a href="/categories/quant/basics/" title="分类于基础知识">基础知识</a></div><span><a href="/quant/basics/%E6%89%93%E6%9D%BF%E5%9F%BA%E7%A1%80/">打板基础</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/courses/" title="分类于课程学习">课程学习</a><i class="ic i-angle-right"></i><a href="/categories/courses/c-statistics/" title="分类于数理统计">数理统计</a></div><span><a href="/courses/c-statistics/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%9F%BA%E7%A1%80/">多元统计基础</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/pc-migration/" title="分类于电脑迁移指南">电脑迁移指南</a></div><span><a href="/pc-migration/Cpp%E6%8F%92%E4%BB%B6/">Cpp插件</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/quant/" title="分类于量化">量化</a><i class="ic i-angle-right"></i><a href="/categories/quant/tutors/" title="分类于从师">从师</a></div><span><a href="/quant/tutors/%E5%88%9B%E7%A5%9E%E6%8D%A2%E6%89%8B%E6%9D%BF%E7%BB%8F%E9%AA%8C%E5%AD%A6%E4%B9%A0/">创神换手板经验学习</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/courses/" title="分类于课程学习">课程学习</a><i class="ic i-angle-right"></i><a href="/categories/courses/c-statistics/" title="分类于数理统计">数理统计</a></div><span><a href="/courses/c-statistics/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/">假设检验</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/internship/" title="分类于实习">实习</a></div><span><a href="/internship/%E6%95%B0%E7%90%86%E5%9F%BA%E7%A1%80/">数理基础</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/pc-migration/" title="分类于电脑迁移指南">电脑迁移指南</a></div><span><a href="/pc-migration/Zotero%E6%94%BB%E7%95%A5/">Zotero攻略</a></span></li></ul></div><div class="rpost pjax"><h2>最新评论</h2><ul class="leancloud-recent-comment" id="new-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2024 -<span itemprop="copyrightYear">2025</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">柳小寒寒子 @ Liuxiaohanhanzi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">136k 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">2:04</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
    path: `LLM/LLM推理加速/`,
    favicon: {
        show: `ヾ(๑• •๑)ﾉﾞ 你好！`,
        hide: `｡°(°˘◠˘°)°｡ 快回来呀`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    nocopy: "false",
    copyright: `复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。`,
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: undefined,
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};
</script><script src="https://s4.zstatic.net/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha384-ZvpUoO&#x2F;+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn&#x2F;6Z&#x2F;hRTt8+pR6L4N2" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha384-Zm+UU4tdcfAm29vg+MTbfu&#x2F;&#x2F;q5B&#x2F;lInMbMCr4T8c9rQFyOv6PlfQYpB5wItcXWe7" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" integrity="sha384-TOxsBplaL96&#x2F;QDWPIUg+ye3v89qSE3s22XNtJMmCeZEep3cVDmXy1zEfZvVv+y2m" crossorigin="anonymous" fetchpriority="high"></script><script src="//fastly.jsdelivr.net/gh/liuxiaohanhanzi/liuxiaohanhanzi.github.io@latest/js/siteInit.js?v=0.4.20" type="module" fetchpriority="high" defer></script></body></html>